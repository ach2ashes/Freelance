{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(True, ['tüm', 'ama', 'eğer', 'defa', 'ya', 'da', 'için', 'bu', 'bazı', 'mı'])"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "import pandas as pd\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import PorterStemmer , SnowballStemmer\n",
    "import re\n",
    "\n",
    "\n",
    "# Check if Turkish stopwords are available in NLTK\n",
    "if 'turkish' in nltk.corpus.stopwords.fileids():\n",
    "    turkish_stopwords = set(nltk.corpus.stopwords.words('turkish'))\n",
    "    turkish_stopwords_available = True\n",
    "else:\n",
    "    turkish_stopwords_available = False\n",
    "    # A basic list of Turkish stopwords, if needed. This should be expanded based on actual use cases.\n",
    "    turkish_stopwords = {\"ve\", \"bu\", \"bir\", \"da\", \"de\", \"en\", \"için\", \"mi\", \"ama\", \"çok\", \"daha\", \"her\"}\n",
    "\n",
    "turkish_stopwords_available, list(turkish_stopwords)[:10] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adapting text processing to use NLTK\n",
    "stemmer = SnowballStemmer(\"english\")\n",
    "\n",
    "def stem_turkish_text_nltk(df, column_name):\n",
    "    stemmed_tweets = []\n",
    "\n",
    "    for tweet in df[column_name]:\n",
    "        # Tokenize the tweet\n",
    "        tweet_tokens = word_tokenize(tweet.lower())\n",
    "        \n",
    "        # Stem each word in the tweet\n",
    "        stemmed_words = [stemmer.stem(word) for word in tweet_tokens if word.isalnum()]\n",
    "        \n",
    "        # Reconstruct the tweet from stemmed words\n",
    "        stemmed_tweet = \" \".join(stemmed_words)\n",
    "        \n",
    "        stemmed_tweets.append(stemmed_tweet)\n",
    "\n",
    "    # Add stemmed tweets as a new column in the DataFrame\n",
    "    df[f\"{column_name}_stemmed\"] = stemmed_tweets\n",
    "    return df\n",
    "\n",
    "# Define the emoji removal pattern\n",
    "emoji_pattern = re.compile(\"[\" \n",
    "                           u\"\\U0001F600-\\U0001F64F\"  # emoticons\n",
    "                           u\"\\U0001F300-\\U0001F5FF\"  # symbols & pictographs\n",
    "                           u\"\\U0001F680-\\U0001F6FF\"  # transport & map symbols\n",
    "                           u\"\\U0001F1E0-\\U0001F1FF\"  # flags (iOS)\n",
    "                           u\"\\U00002702-\\U000027B0\"\n",
    "                           u\"\\U000024C2-\\U0001F251\"\n",
    "                           \"]+\", flags=re.UNICODE)\n",
    "\n",
    "def process_turkish_text_nltk(df, column_name):\n",
    "    turkish_stopwords = set(nltk.corpus.stopwords.words('turkish'))\n",
    "    \n",
    "    processed_tweets = []\n",
    "\n",
    "    for tweet in df[column_name]:\n",
    "        # Convert to lowercase\n",
    "        tweet = tweet.lower()\n",
    "        \n",
    "        # Remove URLs\n",
    "        tweet = re.sub(r\"http\\S+|www\\S+|https\\S+\", '', tweet, flags=re.MULTILINE)\n",
    "        \n",
    "        # Remove user @ references and '#' from tweet\n",
    "        tweet = re.sub(r'\\@\\w+|\\#','', tweet)\n",
    "           # Remove emojis\n",
    "        tweet = emoji_pattern.sub(r'', tweet)\n",
    "        \n",
    "        # Tokenize the tweet\n",
    "        tweet_tokens = word_tokenize(tweet)\n",
    "        \n",
    "        # Remove stopwords\n",
    "        filtered_words = [word for word in tweet_tokens if word not in turkish_stopwords and word.isalnum()]\n",
    "        \n",
    "        \n",
    "        \n",
    "        # Reconstruct the tweet from filtered words\n",
    "        tweet = \" \".join(filtered_words)\n",
    "        \n",
    "        processed_tweets.append(tweet)\n",
    "\n",
    "    # Add processed tweets as a new column in the DataFrame\n",
    "    df[f\"{column_name}_processed\"] = processed_tweets\n",
    "    return df\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[3], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m df \u001b[38;5;241m=\u001b[39mpd\u001b[38;5;241m.\u001b[39mread_excel(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mC:/Users/PC2/Downloads/StemmedTFND_2019_Ver01.xlsx\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\PC2\\anaconda3\\Lib\\site-packages\\pandas\\io\\excel\\_base.py:486\u001b[0m, in \u001b[0;36mread_excel\u001b[1;34m(io, sheet_name, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skiprows, nrows, na_values, keep_default_na, na_filter, verbose, parse_dates, date_parser, date_format, thousands, decimal, comment, skipfooter, storage_options, dtype_backend)\u001b[0m\n\u001b[0;32m    480\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    481\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEngine should not be specified when passing \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    482\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124man ExcelFile - ExcelFile already has the engine set\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    483\u001b[0m     )\n\u001b[0;32m    485\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 486\u001b[0m     data \u001b[38;5;241m=\u001b[39m io\u001b[38;5;241m.\u001b[39mparse(\n\u001b[0;32m    487\u001b[0m         sheet_name\u001b[38;5;241m=\u001b[39msheet_name,\n\u001b[0;32m    488\u001b[0m         header\u001b[38;5;241m=\u001b[39mheader,\n\u001b[0;32m    489\u001b[0m         names\u001b[38;5;241m=\u001b[39mnames,\n\u001b[0;32m    490\u001b[0m         index_col\u001b[38;5;241m=\u001b[39mindex_col,\n\u001b[0;32m    491\u001b[0m         usecols\u001b[38;5;241m=\u001b[39musecols,\n\u001b[0;32m    492\u001b[0m         dtype\u001b[38;5;241m=\u001b[39mdtype,\n\u001b[0;32m    493\u001b[0m         converters\u001b[38;5;241m=\u001b[39mconverters,\n\u001b[0;32m    494\u001b[0m         true_values\u001b[38;5;241m=\u001b[39mtrue_values,\n\u001b[0;32m    495\u001b[0m         false_values\u001b[38;5;241m=\u001b[39mfalse_values,\n\u001b[0;32m    496\u001b[0m         skiprows\u001b[38;5;241m=\u001b[39mskiprows,\n\u001b[0;32m    497\u001b[0m         nrows\u001b[38;5;241m=\u001b[39mnrows,\n\u001b[0;32m    498\u001b[0m         na_values\u001b[38;5;241m=\u001b[39mna_values,\n\u001b[0;32m    499\u001b[0m         keep_default_na\u001b[38;5;241m=\u001b[39mkeep_default_na,\n\u001b[0;32m    500\u001b[0m         na_filter\u001b[38;5;241m=\u001b[39mna_filter,\n\u001b[0;32m    501\u001b[0m         verbose\u001b[38;5;241m=\u001b[39mverbose,\n\u001b[0;32m    502\u001b[0m         parse_dates\u001b[38;5;241m=\u001b[39mparse_dates,\n\u001b[0;32m    503\u001b[0m         date_parser\u001b[38;5;241m=\u001b[39mdate_parser,\n\u001b[0;32m    504\u001b[0m         date_format\u001b[38;5;241m=\u001b[39mdate_format,\n\u001b[0;32m    505\u001b[0m         thousands\u001b[38;5;241m=\u001b[39mthousands,\n\u001b[0;32m    506\u001b[0m         decimal\u001b[38;5;241m=\u001b[39mdecimal,\n\u001b[0;32m    507\u001b[0m         comment\u001b[38;5;241m=\u001b[39mcomment,\n\u001b[0;32m    508\u001b[0m         skipfooter\u001b[38;5;241m=\u001b[39mskipfooter,\n\u001b[0;32m    509\u001b[0m         dtype_backend\u001b[38;5;241m=\u001b[39mdtype_backend,\n\u001b[0;32m    510\u001b[0m     )\n\u001b[0;32m    511\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m    512\u001b[0m     \u001b[38;5;66;03m# make sure to close opened file handles\u001b[39;00m\n\u001b[0;32m    513\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m should_close:\n",
      "File \u001b[1;32mc:\\Users\\PC2\\anaconda3\\Lib\\site-packages\\pandas\\io\\excel\\_base.py:1551\u001b[0m, in \u001b[0;36mExcelFile.parse\u001b[1;34m(self, sheet_name, header, names, index_col, usecols, converters, true_values, false_values, skiprows, nrows, na_values, parse_dates, date_parser, date_format, thousands, comment, skipfooter, dtype_backend, **kwds)\u001b[0m\n\u001b[0;32m   1518\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mparse\u001b[39m(\n\u001b[0;32m   1519\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m   1520\u001b[0m     sheet_name: \u001b[38;5;28mstr\u001b[39m \u001b[38;5;241m|\u001b[39m \u001b[38;5;28mint\u001b[39m \u001b[38;5;241m|\u001b[39m \u001b[38;5;28mlist\u001b[39m[\u001b[38;5;28mint\u001b[39m] \u001b[38;5;241m|\u001b[39m \u001b[38;5;28mlist\u001b[39m[\u001b[38;5;28mstr\u001b[39m] \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1538\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds,\n\u001b[0;32m   1539\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m DataFrame \u001b[38;5;241m|\u001b[39m \u001b[38;5;28mdict\u001b[39m[\u001b[38;5;28mstr\u001b[39m, DataFrame] \u001b[38;5;241m|\u001b[39m \u001b[38;5;28mdict\u001b[39m[\u001b[38;5;28mint\u001b[39m, DataFrame]:\n\u001b[0;32m   1540\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   1541\u001b[0m \u001b[38;5;124;03m    Parse specified sheet(s) into a DataFrame.\u001b[39;00m\n\u001b[0;32m   1542\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1549\u001b[0m \u001b[38;5;124;03m        DataFrame from the passed in Excel file.\u001b[39;00m\n\u001b[0;32m   1550\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m-> 1551\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reader\u001b[38;5;241m.\u001b[39mparse(\n\u001b[0;32m   1552\u001b[0m         sheet_name\u001b[38;5;241m=\u001b[39msheet_name,\n\u001b[0;32m   1553\u001b[0m         header\u001b[38;5;241m=\u001b[39mheader,\n\u001b[0;32m   1554\u001b[0m         names\u001b[38;5;241m=\u001b[39mnames,\n\u001b[0;32m   1555\u001b[0m         index_col\u001b[38;5;241m=\u001b[39mindex_col,\n\u001b[0;32m   1556\u001b[0m         usecols\u001b[38;5;241m=\u001b[39musecols,\n\u001b[0;32m   1557\u001b[0m         converters\u001b[38;5;241m=\u001b[39mconverters,\n\u001b[0;32m   1558\u001b[0m         true_values\u001b[38;5;241m=\u001b[39mtrue_values,\n\u001b[0;32m   1559\u001b[0m         false_values\u001b[38;5;241m=\u001b[39mfalse_values,\n\u001b[0;32m   1560\u001b[0m         skiprows\u001b[38;5;241m=\u001b[39mskiprows,\n\u001b[0;32m   1561\u001b[0m         nrows\u001b[38;5;241m=\u001b[39mnrows,\n\u001b[0;32m   1562\u001b[0m         na_values\u001b[38;5;241m=\u001b[39mna_values,\n\u001b[0;32m   1563\u001b[0m         parse_dates\u001b[38;5;241m=\u001b[39mparse_dates,\n\u001b[0;32m   1564\u001b[0m         date_parser\u001b[38;5;241m=\u001b[39mdate_parser,\n\u001b[0;32m   1565\u001b[0m         date_format\u001b[38;5;241m=\u001b[39mdate_format,\n\u001b[0;32m   1566\u001b[0m         thousands\u001b[38;5;241m=\u001b[39mthousands,\n\u001b[0;32m   1567\u001b[0m         comment\u001b[38;5;241m=\u001b[39mcomment,\n\u001b[0;32m   1568\u001b[0m         skipfooter\u001b[38;5;241m=\u001b[39mskipfooter,\n\u001b[0;32m   1569\u001b[0m         dtype_backend\u001b[38;5;241m=\u001b[39mdtype_backend,\n\u001b[0;32m   1570\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds,\n\u001b[0;32m   1571\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\PC2\\anaconda3\\Lib\\site-packages\\pandas\\io\\excel\\_base.py:751\u001b[0m, in \u001b[0;36mBaseExcelReader.parse\u001b[1;34m(self, sheet_name, header, names, index_col, usecols, dtype, true_values, false_values, skiprows, nrows, na_values, verbose, parse_dates, date_parser, date_format, thousands, decimal, comment, skipfooter, dtype_backend, **kwds)\u001b[0m\n\u001b[0;32m    748\u001b[0m     sheet \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_sheet_by_index(asheetname)\n\u001b[0;32m    750\u001b[0m file_rows_needed \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_calc_rows(header, index_col, skiprows, nrows)\n\u001b[1;32m--> 751\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_sheet_data(sheet, file_rows_needed)\n\u001b[0;32m    752\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(sheet, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mclose\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m    753\u001b[0m     \u001b[38;5;66;03m# pyxlsb opens two TemporaryFiles\u001b[39;00m\n\u001b[0;32m    754\u001b[0m     sheet\u001b[38;5;241m.\u001b[39mclose()\n",
      "File \u001b[1;32mc:\\Users\\PC2\\anaconda3\\Lib\\site-packages\\pandas\\io\\excel\\_openpyxl.py:602\u001b[0m, in \u001b[0;36mOpenpyxlReader.get_sheet_data\u001b[1;34m(self, sheet, file_rows_needed)\u001b[0m\n\u001b[0;32m    600\u001b[0m data: \u001b[38;5;28mlist\u001b[39m[\u001b[38;5;28mlist\u001b[39m[Scalar]] \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m    601\u001b[0m last_row_with_data \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m\n\u001b[1;32m--> 602\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m row_number, row \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(sheet\u001b[38;5;241m.\u001b[39mrows):\n\u001b[0;32m    603\u001b[0m     converted_row \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_convert_cell(cell) \u001b[38;5;28;01mfor\u001b[39;00m cell \u001b[38;5;129;01min\u001b[39;00m row]\n\u001b[0;32m    604\u001b[0m     \u001b[38;5;28;01mwhile\u001b[39;00m converted_row \u001b[38;5;129;01mand\u001b[39;00m converted_row[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m    605\u001b[0m         \u001b[38;5;66;03m# trim trailing empty elements\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\PC2\\anaconda3\\Lib\\site-packages\\openpyxl\\worksheet\\_read_only.py:90\u001b[0m, in \u001b[0;36mReadOnlyWorksheet._cells_by_row\u001b[1;34m(self, min_col, min_row, max_col, max_row, values_only)\u001b[0m\n\u001b[0;32m     88\u001b[0m \u001b[38;5;66;03m# return cells from a row\u001b[39;00m\n\u001b[0;32m     89\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m counter \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m idx:\n\u001b[1;32m---> 90\u001b[0m     row \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_row(row, min_col, max_col, values_only)\n\u001b[0;32m     91\u001b[0m     counter \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m     92\u001b[0m     \u001b[38;5;28;01myield\u001b[39;00m row\n",
      "File \u001b[1;32mc:\\Users\\PC2\\anaconda3\\Lib\\site-packages\\openpyxl\\worksheet\\_read_only.py:121\u001b[0m, in \u001b[0;36mReadOnlyWorksheet._get_row\u001b[1;34m(self, row, min_col, max_col, values_only)\u001b[0m\n\u001b[0;32m    119\u001b[0m         new_row[idx] \u001b[38;5;241m=\u001b[39m cell[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mvalue\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[0;32m    120\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m values_only:\n\u001b[1;32m--> 121\u001b[0m             new_row[idx] \u001b[38;5;241m=\u001b[39m ReadOnlyCell(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mcell)\n\u001b[0;32m    123\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mtuple\u001b[39m(new_row)\n",
      "File \u001b[1;32mc:\\Users\\PC2\\anaconda3\\Lib\\site-packages\\openpyxl\\cell\\read_only.py:20\u001b[0m, in \u001b[0;36mReadOnlyCell.__init__\u001b[1;34m(self, sheet, row, column, value, data_type, style_id)\u001b[0m\n\u001b[0;32m     18\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumn \u001b[38;5;241m=\u001b[39m column\n\u001b[0;32m     19\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdata_type \u001b[38;5;241m=\u001b[39m data_type\n\u001b[1;32m---> 20\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mvalue \u001b[38;5;241m=\u001b[39m value\n\u001b[0;32m     21\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_style_id \u001b[38;5;241m=\u001b[39m style_id\n",
      "File \u001b[1;32mc:\\Users\\PC2\\anaconda3\\Lib\\site-packages\\openpyxl\\cell\\read_only.py:112\u001b[0m, in \u001b[0;36mReadOnlyCell.value\u001b[1;34m(self, value)\u001b[0m\n\u001b[0;32m    108\u001b[0m \u001b[38;5;129m@property\u001b[39m\n\u001b[0;32m    109\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mvalue\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    110\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_value\n\u001b[1;32m--> 112\u001b[0m \u001b[38;5;129m@value\u001b[39m\u001b[38;5;241m.\u001b[39msetter\n\u001b[0;32m    113\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mvalue\u001b[39m(\u001b[38;5;28mself\u001b[39m, value):\n\u001b[0;32m    114\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_value \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    115\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCell is read only\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "df =pd.read_excel(\"C:/Users/PC2/Downloads/StemmedTFND_2019_Ver01.xlsx\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = process_turkish_text_nltk(df,\"Orj_Text\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = stem_turkish_text_nltk(df,\"Orj_Text_processed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from textblob import TextBlob\n",
    "\n",
    "def sentiment_analysis(df, column_name):\n",
    "    sentiments = []\n",
    "\n",
    "    for tweet in df[column_name]:\n",
    "        # Create a TextBlob object\n",
    "        blob = TextBlob(tweet)\n",
    "        \n",
    "        # Get the sentiment polarity\n",
    "        polarity = blob.sentiment.polarity\n",
    "        \n",
    "        # Determine sentiment category\n",
    "        if polarity > 0:\n",
    "            sentiment = 'Positive'\n",
    "        elif polarity < 0:\n",
    "            sentiment = 'Negative'\n",
    "        else:\n",
    "            sentiment = 'Neutral'\n",
    "        \n",
    "        sentiments.append(sentiment)\n",
    "\n",
    "    # Add sentiment categories to a new column in the DataFrame\n",
    "    df[f\"{column_name}_sentiment\"] = sentiments\n",
    "    return df\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = sentiment_analysis(df,\"Orj_Text\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Orj_Text_sentiment\n",
       "Neutral     89603\n",
       "Positive     7928\n",
       "Negative     1540\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_excel(\"out.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting fpdf\n",
      "  Downloading fpdf-1.7.2.tar.gz (39 kB)\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "Building wheels for collected packages: fpdf\n",
      "  Building wheel for fpdf (setup.py): started\n",
      "  Building wheel for fpdf (setup.py): finished with status 'done'\n",
      "  Created wheel for fpdf: filename=fpdf-1.7.2-py2.py3-none-any.whl size=40713 sha256=1cba3d97b9765a73544e300b2c9b55b5907e325542ea76c979ef43e3f6dc8f4b\n",
      "  Stored in directory: c:\\users\\pc2\\appdata\\local\\pip\\cache\\wheels\\65\\4f\\66\\bbda9866da446a72e206d6484cd97381cbc7859a7068541c36\n",
      "Successfully built fpdf\n",
      "Installing collected packages: fpdf\n",
      "Successfully installed fpdf-1.7.2\n"
     ]
    }
   ],
   "source": [
    "!pip install fpdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'SBAI.ACHRAF_SES209.pdf'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from fpdf import FPDF\n",
    "\n",
    "class PDF(FPDF):\n",
    "    def header(self):\n",
    "        self.set_font('Arial', 'B', 12)\n",
    "        self.cell(0, 10, 'Chasse au Trésor en Réalité Augmentée', 0, 1, 'C')\n",
    "\n",
    "    def footer(self):\n",
    "        self.set_y(-15)\n",
    "        self.set_font('Arial', 'I', 8)\n",
    "        self.cell(0, 10, f'Page {self.page_no()}', 0, 0, 'C')\n",
    "\n",
    "pdf = PDF()\n",
    "pdf.add_page()\n",
    "pdf.set_font(\"Arial\", size=10)\n",
    "\n",
    "content = \"\"\"\n",
    "Hack d'Acquisition : Chasse au Trésor en Réalité Augmentée (RA)\n",
    "\n",
    "Concept:\n",
    "Inspiré par le succès de jeux comme Pokémon GO, ce hack utilise la réalité augmentée pour créer une chasse au trésor engageante et immersive dans le monde réel, où les participants peuvent découvrir et gagner des récompenses liées à votre produit ou service. Cette approche transforme l'acquisition de clients en une expérience ludique et mémorable.\n",
    "\n",
    "Mise en Œuvre:\n",
    "1. Développement d'une Application de RA: Créer une application simple de réalité augmentée qui guide les utilisateurs à travers une chasse au trésor dans leur ville ou quartier, avec des indices et des énigmes basés sur l'emplacement.\n",
    "2. Intégration des Produits/Services: Les \"trésors\" peuvent être des échantillons de produits, des codes promotionnels exclusifs, ou des expériences uniques liées à votre marque.\n",
    "3. Engagement Communautaire: Encourager le partage sur les réseaux sociaux en offrant des récompenses supplémentaires pour les publications, créant ainsi un buzz organique.\n",
    "\n",
    "Avantages:\n",
    "- Expérience Immersive: Offre une expérience utilisateur captivante qui se démarque dans un paysage publicitaire saturé.\n",
    "- Viralité Potentielle: La nature ludique et innovante de la campagne encourage le partage et la participation communautaire.\n",
    "- Données Précieuses: Collecte des données sur les préférences et comportements des utilisateurs en fonction de leur interaction avec l'application.\n",
    "\n",
    "Impact:\n",
    "Ce hack non seulement attire de nouveaux clients en leur offrant une expérience unique, mais crée également un sentiment de communauté et d'engagement autour de la marque. En transformant l'acquisition en un jeu, vous générez de l'enthousiasme et de la visibilité, tout en offrant une plateforme pour présenter vos produits de manière interactive.\n",
    "\"\"\"\n",
    "\n",
    "# Replace problematic characters\n",
    "content = content.replace(u\"\\u0152\", \"OE\").replace(u\"\\u0153\", \"oe\")\n",
    "\n",
    "pdf.multi_cell(0, 10, content)\n",
    "\n",
    "# Save the pdf with name .pdf\n",
    "pdf_file_path = 'SBAI.ACHRAF_SES209.pdf'\n",
    "pdf.output(pdf_file_path)\n",
    "\n",
    "pdf_file_path\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
