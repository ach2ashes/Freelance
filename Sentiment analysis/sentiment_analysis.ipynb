{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importing and preprocessing\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "\n",
    "# Load JSON data\n",
    "with open('friends_train.json') as f:\n",
    "    data = json.load(f)\n",
    "\n",
    "\n",
    "# Create dataframes for each list in data\n",
    "dfs = [pd.DataFrame(lst) for lst in data]\n",
    "\n",
    "# Concatenate dataframes\n",
    "df = pd.concat(dfs, ignore_index=True)\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('friends_test.json') as f:\n",
    "    data = json.load(f)\n",
    "\n",
    "\n",
    "# Create dataframes for each list in data\n",
    "dfs = [pd.DataFrame(lst) for lst in data]\n",
    "\n",
    "# Concatenate dataframes\n",
    "test = pd.concat(dfs, ignore_index=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>speaker</th>\n",
       "      <th>utterance</th>\n",
       "      <th>emotion</th>\n",
       "      <th>annotation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Chandler</td>\n",
       "      <td>also I was the point person on my companys tr...</td>\n",
       "      <td>neutral</td>\n",
       "      <td>4100000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>The Interviewer</td>\n",
       "      <td>You mustve had your hands full.</td>\n",
       "      <td>neutral</td>\n",
       "      <td>5000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Chandler</td>\n",
       "      <td>That I did. That I did.</td>\n",
       "      <td>neutral</td>\n",
       "      <td>5000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>The Interviewer</td>\n",
       "      <td>So lets talk a little bit about your duties.</td>\n",
       "      <td>neutral</td>\n",
       "      <td>5000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Chandler</td>\n",
       "      <td>My duties?  All right.</td>\n",
       "      <td>surprise</td>\n",
       "      <td>2000030</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           speaker                                          utterance  \\\n",
       "0         Chandler  also I was the point person on my companys tr...   \n",
       "1  The Interviewer                   You mustve had your hands full.   \n",
       "2         Chandler                            That I did. That I did.   \n",
       "3  The Interviewer      So lets talk a little bit about your duties.   \n",
       "4         Chandler                             My duties?  All right.   \n",
       "\n",
       "    emotion annotation  \n",
       "0   neutral    4100000  \n",
       "1   neutral    5000000  \n",
       "2   neutral    5000000  \n",
       "3   neutral    5000000  \n",
       "4  surprise    2000030  "
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['neutral', 'surprise', 'fear', 'non-neutral', 'joy', 'sadness',\n",
       "       'anger', 'disgust'], dtype=object)"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.emotion.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['emotion'].replace([\"joy\",\"surprise\"],\"positive\",inplace=True)\n",
    "df['emotion'].replace([\"fear\",\"sadness\",\"anger\",\"disgust\"],\"negative\",inplace=True)\n",
    "df = df.drop(df[df['emotion'] == 'non-neutral'].index)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "test['emotion'].replace([\"joy\",\"surprise\"],\"positive\",inplace=True)\n",
    "test['emotion'].replace([\"fear\",\"sadness\",\"anger\",\"disgust\"],\"negative\",inplace=True)\n",
    "test = test.drop(test[test['emotion'] == 'non-neutral'].index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import string\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "def preprocess_text(text):\n",
    "    # Lowercase the text\n",
    "    text = text.lower()\n",
    "    \n",
    "    # Remove URLs\n",
    "    text = re.sub(r'http\\S+', '', text)\n",
    "    \n",
    "    # Remove usernames and hashtags\n",
    "    text = re.sub(r'@\\S+|#\\S+', '', text)\n",
    "    \n",
    "    # Remove punctuation\n",
    "    text = text.translate(str.maketrans('', '', string.punctuation))\n",
    "    \n",
    "    # Tokenize the text\n",
    "    tokens = word_tokenize(text)\n",
    "    \n",
    "    # Remove stopwords\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    tokens = [word for word in tokens if word not in stop_words]\n",
    "    \n",
    "    # Lemmatize the tokens\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    tokens = [lemmatizer.lemmatize(token) for token in tokens]\n",
    "    \n",
    "    # Join the tokens back into text\n",
    "    text = ' '.join(tokens)\n",
    "    \n",
    "    return text"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NLTK default Sentiment analyzer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentiment analysis accuracy: 45.97%\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "import pandas as pd\n",
    "from nltk.sentiment import SentimentIntensityAnalyzer\n",
    "sia = SentimentIntensityAnalyzer()\n",
    "def get_sentiment(text):\n",
    "    scores = sia.polarity_scores(text)\n",
    "    if scores['compound'] > 0:\n",
    "        return 'positive'\n",
    "    elif scores['compound'] < 0:\n",
    "        return 'negative'\n",
    "    else:\n",
    "        return 'neutral'\n",
    "test[\"utterance\"] = test[\"utterance\"].apply(preprocess_text)\n",
    "test['sentiment'] = test['utterance'].apply(get_sentiment)\n",
    "accuracy = (test['sentiment'] == test['emotion']).mean()\n",
    "print(f'Sentiment analysis accuracy: {accuracy:.2%}')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['neutral', 'positive', 'negative'], dtype=object)"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.emotion.unique()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ML Algos (Multinomial NB , Logistic Regression and XGboost )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training MultinomialNB with (1, 1) n-grams...\n",
      "MultinomialNB Accuracy: 0.6230319388214125\n",
      "MultinomialNB Confusion Matrix:\n",
      "[[   6  318   22]\n",
      " [   1 1252   34]\n",
      " [   1  462  127]]\n",
      "\n",
      "Training MultinomialNB with (1, 2) n-grams...\n",
      "MultinomialNB Accuracy: 0.6158344579397211\n",
      "MultinomialNB Confusion Matrix:\n",
      "[[   3  332   11]\n",
      " [   1 1272   14]\n",
      " [   0  496   94]]\n",
      "\n",
      "Training MultinomialNB with (1, 3) n-grams...\n",
      "MultinomialNB Accuracy: 0.6122357174988754\n",
      "MultinomialNB Confusion Matrix:\n",
      "[[   3  332   11]\n",
      " [   1 1275   11]\n",
      " [   0  507   83]]\n",
      "\n",
      "Training LogisticRegression with (1, 1) n-grams...\n",
      "LogisticRegression Accuracy: 0.631578947368421\n",
      "LogisticRegression Confusion Matrix:\n",
      "[[  42  265   39]\n",
      " [  33 1133  121]\n",
      " [   9  352  229]]\n",
      "\n",
      "Training LogisticRegression with (1, 2) n-grams...\n",
      "LogisticRegression Accuracy: 0.631578947368421\n",
      "LogisticRegression Confusion Matrix:\n",
      "[[  40  277   29]\n",
      " [  32 1146  109]\n",
      " [   6  366  218]]\n",
      "\n",
      "Training LogisticRegression with (1, 3) n-grams...\n",
      "LogisticRegression Accuracy: 0.6320287899235267\n",
      "LogisticRegression Confusion Matrix:\n",
      "[[  35  284   27]\n",
      " [  31 1155  101]\n",
      " [   6  369  215]]\n",
      "\n",
      "Training XGBClassifier with (1, 1) n-grams...\n",
      "[15:00:22] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "XGBClassifier Accuracy: 0.6230319388214125\n",
      "XGBClassifier Confusion Matrix:\n",
      "[[  47  268   31]\n",
      " [  53 1161   73]\n",
      " [  18  395  177]]\n",
      "\n",
      "Training XGBClassifier with (1, 2) n-grams...\n",
      "[15:00:23] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "XGBClassifier Accuracy: 0.6198830409356725\n",
      "XGBClassifier Confusion Matrix:\n",
      "[[  49  262   35]\n",
      " [  61 1136   90]\n",
      " [  14  383  193]]\n",
      "\n",
      "Training XGBClassifier with (1, 3) n-grams...\n",
      "[15:00:25] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "XGBClassifier Accuracy: 0.6131354026090868\n",
      "XGBClassifier Confusion Matrix:\n",
      "[[  51  258   37]\n",
      " [  68 1123   96]\n",
      " [  14  387  189]]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "\n",
    "# Preprocess data\n",
    "df['utterance'] = df['utterance'].apply(preprocess_text)\n",
    "df['emotion'] = df['emotion'].astype('category')\n",
    "\n",
    "# Split dataset into training and testing sets\n",
    "X = df['utterance']\n",
    "y = df['emotion']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# Define models\n",
    "models = [('MultinomialNB', MultinomialNB()), \n",
    "          ('LogisticRegression', LogisticRegression()), \n",
    "          ('XGBClassifier', XGBClassifier())]\n",
    "# Define n-gram ranges to try\n",
    "ngram_ranges = [(1, 1), (1, 2), (1, 3)]\n",
    "\n",
    "\n",
    "# Train and evaluate models\n",
    "# Preprocess test data\n",
    "test['utterance'] = test['utterance'].apply(preprocess_text)\n",
    "test['emotion'] = test['emotion'].astype('category')\n",
    "\n",
    "# Evaluate models on test data\n",
    "for name, model in models:\n",
    "    for ngram_range in ngram_ranges:\n",
    "        print(f'Training {name} with {ngram_range} n-grams...')\n",
    "        # Define pipeline\n",
    "        pipeline = Pipeline([\n",
    "            ('tfidf', TfidfVectorizer(ngram_range=ngram_range)),\n",
    "            ('clf', model)\n",
    "        ])\n",
    "        # Fit pipeline on training data\n",
    "        pipeline.fit(X_train, y_train)\n",
    "        # Predict on test data\n",
    "        y_pred = pipeline.predict(test['utterance'])\n",
    "        # Calculate accuracy and confusion matrix\n",
    "        acc = accuracy_score(test['emotion'], y_pred)\n",
    "        cm = confusion_matrix(test['emotion'], y_pred)\n",
    "        # Print results\n",
    "        print(f'{name} Accuracy: {acc}')\n",
    "        print(f'{name} Confusion Matrix:\\n{cm}\\n')\n",
    "\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "171/171 [==============================] - 3s 17ms/step - loss: 1.0136 - accuracy: 0.5463 - val_loss: 0.9303 - val_accuracy: 0.5647\n",
      "Epoch 2/20\n",
      "171/171 [==============================] - 3s 19ms/step - loss: 0.8464 - accuracy: 0.6229 - val_loss: 0.8830 - val_accuracy: 0.5896\n",
      "Epoch 3/20\n",
      "171/171 [==============================] - 3s 20ms/step - loss: 0.6068 - accuracy: 0.7522 - val_loss: 0.9092 - val_accuracy: 0.5903\n",
      "Epoch 4/20\n",
      "171/171 [==============================] - 3s 19ms/step - loss: 0.4190 - accuracy: 0.8299 - val_loss: 1.1098 - val_accuracy: 0.5611\n",
      "Epoch 5/20\n",
      "171/171 [==============================] - 3s 18ms/step - loss: 0.3180 - accuracy: 0.8683 - val_loss: 1.2388 - val_accuracy: 0.5713\n",
      "Epoch 6/20\n",
      "171/171 [==============================] - 3s 19ms/step - loss: 0.2626 - accuracy: 0.8881 - val_loss: 1.4346 - val_accuracy: 0.5977\n",
      "Epoch 7/20\n",
      "171/171 [==============================] - 3s 18ms/step - loss: 0.2310 - accuracy: 0.8963 - val_loss: 1.6838 - val_accuracy: 0.5538\n",
      "Epoch 8/20\n",
      "171/171 [==============================] - 3s 18ms/step - loss: 0.2092 - accuracy: 0.9060 - val_loss: 1.8188 - val_accuracy: 0.5772\n",
      "Epoch 9/20\n",
      "171/171 [==============================] - 3s 18ms/step - loss: 0.1934 - accuracy: 0.9144 - val_loss: 1.9216 - val_accuracy: 0.5779\n",
      "Epoch 10/20\n",
      "171/171 [==============================] - 3s 17ms/step - loss: 0.1922 - accuracy: 0.9097 - val_loss: 1.9722 - val_accuracy: 0.5830\n",
      "Epoch 11/20\n",
      "171/171 [==============================] - 3s 17ms/step - loss: 0.1803 - accuracy: 0.9168 - val_loss: 2.1288 - val_accuracy: 0.5918\n",
      "Epoch 12/20\n",
      "171/171 [==============================] - 3s 19ms/step - loss: 0.1764 - accuracy: 0.9190 - val_loss: 2.2800 - val_accuracy: 0.5823\n",
      "Epoch 13/20\n",
      "171/171 [==============================] - 3s 18ms/step - loss: 0.1764 - accuracy: 0.9151 - val_loss: 2.3455 - val_accuracy: 0.5560\n",
      "Epoch 14/20\n",
      "171/171 [==============================] - 3s 17ms/step - loss: 0.1813 - accuracy: 0.9137 - val_loss: 2.2121 - val_accuracy: 0.5874\n",
      "Epoch 15/20\n",
      "171/171 [==============================] - 3s 17ms/step - loss: 0.1758 - accuracy: 0.9173 - val_loss: 2.3955 - val_accuracy: 0.5596\n",
      "Epoch 16/20\n",
      "171/171 [==============================] - 3s 17ms/step - loss: 0.1693 - accuracy: 0.9181 - val_loss: 2.6049 - val_accuracy: 0.5699\n",
      "Epoch 17/20\n",
      "171/171 [==============================] - 3s 17ms/step - loss: 0.1655 - accuracy: 0.9199 - val_loss: 2.6775 - val_accuracy: 0.5706\n",
      "Epoch 18/20\n",
      "171/171 [==============================] - 3s 18ms/step - loss: 0.1617 - accuracy: 0.9190 - val_loss: 2.7475 - val_accuracy: 0.5596\n",
      "Epoch 19/20\n",
      "171/171 [==============================] - 3s 17ms/step - loss: 0.1604 - accuracy: 0.9208 - val_loss: 2.7682 - val_accuracy: 0.5735\n",
      "Epoch 20/20\n",
      "171/171 [==============================] - 3s 19ms/step - loss: 0.1665 - accuracy: 0.9199 - val_loss: 2.6702 - val_accuracy: 0.5823\n",
      "70/70 - 0s - loss: 2.7878 - accuracy: 0.5753 - 446ms/epoch - 6ms/step\n",
      "Test Accuracy: 0.5753486156463623\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# Encode the target variable\n",
    "le = LabelEncoder()\n",
    "df['emotion'] = le.fit_transform(df['emotion'])\n",
    "test['emotion'] = le.fit_transform(test['emotion'])\n",
    "\n",
    "# Split the dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(df['utterance'], df['emotion'], test_size=0.2, random_state=42)\n",
    "\n",
    "# Tokenize the text data\n",
    "tokenizer = tf.keras.preprocessing.text.Tokenizer()\n",
    "tokenizer.fit_on_texts(X_train)\n",
    "\n",
    "# Convert text to sequences\n",
    "X_train_seq = tokenizer.texts_to_sequences(X_train)\n",
    "X_test_seq = tokenizer.texts_to_sequences(test[\"utterance\"])\n",
    "y_test = test[\"emotion\"]\n",
    "\n",
    "# Pad the sequences\n",
    "max_len = 100\n",
    "X_train_pad = tf.keras.preprocessing.sequence.pad_sequences(X_train_seq, maxlen=max_len, padding='post', truncating='post')\n",
    "X_test_pad = tf.keras.preprocessing.sequence.pad_sequences(X_test_seq, maxlen=max_len, padding='post', truncating='post')\n",
    "\n",
    "# Build the model\n",
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Embedding(input_dim=len(tokenizer.word_index) + 1, output_dim=64, input_length=max_len),\n",
    "    tf.keras.layers.Conv1D(128, 5, activation='relu'),\n",
    "    tf.keras.layers.GlobalMaxPooling1D(),\n",
    "    tf.keras.layers.Dense(128, activation='relu'),\n",
    "    tf.keras.layers.Dropout(0.2),\n",
    "    tf.keras.layers.Dense(64, activation='relu'),\n",
    "    tf.keras.layers.Dropout(0.2),\n",
    "    tf.keras.layers.Dense(4, activation='softmax')\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "model.compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "history = model.fit(X_train_pad, y_train, epochs=20, batch_size=32, validation_split=0.2)\n",
    "\n",
    "# Evaluate the model on test set\n",
    "test_loss, test_acc = model.evaluate(X_test_pad, y_test, verbose=2)\n",
    "print('Test Accuracy:', test_acc)\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
